# -*- coding: utf-8 -*-
"""ResQ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nGDmkuVuIGdIfnNASpEBJXOywkWcP3Nx
"""

!pip install ultralytics opencv-python pillow matplotlib

from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

model = YOLO("yolov8m.pt")   # even better

from google.colab import files

uploaded = files.upload()
image_path = list(uploaded.keys())[0]
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

print("Image loaded successfully")

def split_tiles(img, tiles=2):
    h, w, _ = img.shape
    tile_h = h // tiles
    tile_w = w // tiles

    tiles_list = []

    for i in range(tiles):
        for j in range(tiles):
            y1 = i * tile_h
            y2 = (i + 1) * tile_h
            x1 = j * tile_w
            x2 = (j + 1) * tile_w

            tiles_list.append((img[y1:y2, x1:x2], x1, y1))

    return tiles_list

tiles_list = split_tiles(image_rgb)
print("Tiles created:", len(tiles_list))

victims = []
victim_id = 0

for tile, ox, oy in tiles_list:
    results = model(tile)

    for r in results:
        boxes = r.boxes.xyxy.cpu().numpy()
        confs = r.boxes.conf.cpu().numpy()
        classes = r.boxes.cls.cpu().numpy()

        for box, conf, cls in zip(boxes, confs, classes):
            if int(cls) == 0:  # class 0 = person
                x1, y1, x2, y2 = box
                victims.append({
                    "id": victim_id,
                    "x1": int(x1 + ox),
                    "y1": int(y1 + oy),
                    "x2": int(x2 + ox),
                    "y2": int(y2 + oy),
                    "confidence": float(conf)
                })
                victim_id += 1

print("Victims detected:", len(victims))

def compute_risk_score(v):
    area = (v["x2"] - v["x1"]) * (v["y2"] - v["y1"])
    aspect_ratio = (v["x2"] - v["x1"]) / ((v["y2"] - v["y1"]) + 1e-6)
    conf = v["confidence"]

    area_score = 1 / (area + 1)
    posture_score = abs(aspect_ratio - 1)
    confidence_score = (1 - conf)

    score = 0.5*area_score + 0.3*posture_score + 0.2*confidence_score
    return score

def assign_priority(score):
    if score > 0.7:
        return "HIGH"
    elif score > 0.4:
        return "MEDIUM"
    else:
        return "LOW"

for v in victims:
    v["risk_score"] = compute_risk_score(v)
    v["priority"] = assign_priority(v["risk_score"])

output = image_rgb.copy()

for v in victims:
    color = (0,255,0)
    if v["priority"] == "HIGH":
        color = (255,0,0)
    elif v["priority"] == "MEDIUM":
        color = (255,255,0)

    cv2.rectangle(output, (v["x1"], v["y1"]), (v["x2"], v["y2"]), color, 2)
    cv2.putText(output, f"ID:{v['id']} {v['priority']}",
                (v["x1"], v["y1"]-5),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

output_img = Image.fromarray(output)
display(output_img)

for v in victims:
    print(f"Victim {v['id']} | Score:{v['risk_score']:.2f} | Priority:{v['priority']}")

import os
os.makedirs("victim_crops", exist_ok=True)

for v in victims:
    crop = image_rgb[v["y1"]:v["y2"], v["x1"]:v["x2"]]
    path = f"victim_crops/victim_{v['id']}.png"
    Image.fromarray(crop).save(path)

print("Victim crops saved for Stage-3 review")

from IPython.display import display

for v in victims:
    print(f"Victim {v['id']} â€” Current Priority: {v['priority']}")
    display(Image.open(f"victim_crops/victim_{v['id']}.png"))
    print("-" * 40)

selected_id = int(input("Enter Victim ID for close-view re-scan: "))

selected_victim = None
for v in victims:
    if v["id"] == selected_id:
        selected_victim = v
        break

if selected_victim:
    print(f"Selected Victim {selected_id}")
else:
    print("Invalid ID")

from google.colab import files

print("Upload close-view image of the selected region...")
uploaded = files.upload()

close_img_path = list(uploaded.keys())[0]
close_img = cv2.imread(close_img_path)
close_img = cv2.cvtColor(close_img, cv2.COLOR_BGR2RGB)

display(Image.fromarray(close_img))

results = model(close_img)

close_boxes = []

for r in results:
    boxes = r.boxes.xyxy.cpu().numpy()
    confs = r.boxes.conf.cpu().numpy()
    classes = r.boxes.cls.cpu().numpy()

    for box, conf, cls in zip(boxes, confs, classes):
        if int(cls) == 0:  # person
            x1,y1,x2,y2 = map(int, box)
            close_boxes.append({
                "x1":x1,"y1":y1,"x2":x2,"y2":y2,
                "confidence":float(conf)
            })

print("Close-view detections:", len(close_boxes))

refined = close_boxes[0]  # assuming one person in close frame

def refined_risk_score(b):
    area = (b["x2"] - b["x1"]) * (b["y2"] - b["y1"])
    aspect = (b["x2"] - b["x1"]) / ((b["y2"] - b["y1"]) + 1e-6)
    conf = b["confidence"]

    area_score = 1 / (area + 1)
    posture_score = abs(aspect - 1)
    confidence_score = (1 - conf)

    score = (
        0.45 * area_score +
        0.35 * posture_score +
        0.20 * confidence_score
    )
    return score

refined_score = refined_risk_score(refined)

def new_priority(score):
    if score > 0.7:
        return "HIGH"
    elif score > 0.4:
        return "MEDIUM"
    else:
        return "LOW"

refined_priority = new_priority(refined_score)

print(f"\nVictim {selected_id}")
print(f"Old Priority  : {selected_victim['priority']}")
print(f"Refined Score : {refined_score:.2f}")
print(f"New Priority  : {refined_priority}")

selected_victim["refined_score"] = refined_score
selected_victim["priority"] = refined_priority
selected_victim["stage"] = "REFINED"

from PIL import Image
import cv2

dummy_map = cv2.imread("dummy_map.jpg")   # or whatever name
dummy_map = cv2.cvtColor(dummy_map, cv2.COLOR_BGR2RGB)

print("Dummy map loaded")
display(Image.fromarray(dummy_map))

h_img, w_img, _ = image_rgb.shape
dummy_map_resized = cv2.resize(dummy_map, (w_img, h_img))

for v in victims:
    cx = (v["x1"] + v["x2"]) / 2
    cy = (v["y1"] + v["y2"]) / 2

    v["nx"] = cx / w_img
    v["ny"] = cy / h_img

map_dummy_view = dummy_map_resized.copy()

for v in victims:

    px = int(v["nx"] * w_img)
    py = int(v["ny"] * h_img)

    label = f"ID:{v['id']} | {v['priority']}"

    # map-style pin
    cv2.circle(map_dummy_view, (px, py), 8, (255,0,0), -1)
    cv2.line(map_dummy_view, (px, py), (px, py+20), (255,0,0), 2)

    cv2.putText(
        map_dummy_view,
        label,
        (px+10, py-10),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.55,
        (255,0,0),
        2
    )

display(Image.fromarray(map_dummy_view))

BOT_TOKEN = "8492000668:AAFBC8eGDbnuK3GgpF1Jx8juk2kOGp_tCps"
CHAT_ID = "-5114857613"

map_path = "map_snapshot.png"
Image.fromarray(map_dummy_view).save(map_path)
print("Dummy map snapshot saved")

close_view_path = "close_view_victim.png"
Image.fromarray(close_img).save(close_view_path)
print("Close view image saved")

import requests

def send_victim_alert(victim):

    text_message = f"""
ðŸš¨ CSSR VISUAL RISK ALERT

Victim ID: {victim['id']}
Priority : {victim['priority']}
Risk Score: {victim['risk_score']:.2f}

Status: ACTIVE (Human verification required)

Note: This is a visual-risk indicator, not medical triage.
"""

    url = f"https://api.telegram.org/bot8492000668:AAFBC8eGDbnuK3GgpF1Jx8juk2kOGp_tCps/sendMessage"

    requests.post(url, data={
        "chat_id": CHAT_ID,
        "text": text_message
    })

print("Text alert prepared")

url = f"https://api.telegram.org/bot8492000668:AAFBC8eGDbnuK3GgpF1Jx8juk2kOGp_tCps/sendPhoto"

with open(close_view_path, "rb") as img_file:
    requests.post(url, data={"chat_id": CHAT_ID},
                  files={"photo": img_file})

print("Close-view image sent")

with open(map_path, "rb") as img_file:
    requests.post(url, data={"chat_id": CHAT_ID},
                  files={"photo": img_file})

print("Map snapshot sent")

for v in victims:
    if v["priority"] == "HIGH":
        print(f"Sending alert for Victim {v['id']}")
        send_victim_alert(v)